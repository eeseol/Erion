{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPP7QrRTS8+BwBsMGi70QRT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4aSHQuZBzx2","executionInfo":{"status":"ok","timestamp":1722186181140,"user_tz":-540,"elapsed":20828,"user":{"displayName":"최이설/메카트로닉스전공/학생","userId":"15230576164295330294"}},"outputId":"8a8a8c3a-84b7-4590-be01-b35c7d9959de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"]},{"cell_type":"code","source":["!ln -s /content/gdrive/My\\ Drive/ /mydrive"],"metadata":{"id":"r9Qro0JZB-Iy","executionInfo":{"status":"ok","timestamp":1722186184381,"user_tz":-540,"elapsed":332,"user":{"displayName":"최이설/메카트로닉스전공/학생","userId":"15230576164295330294"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%cd /mydrive/yolov4/darknet"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YtOZL5ibCAB5","executionInfo":{"status":"ok","timestamp":1722186596976,"user_tz":-540,"elapsed":338,"user":{"displayName":"최이설/메카트로닉스전공/학생","userId":"15230576164295330294"}},"outputId":"d77a49ba-a111-4243-aceb-57bb28e9adad"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/yolov4/darknet\n"]}]},{"cell_type":"code","source":["!chmod +x ./darknet"],"metadata":{"id":"Yy4Dul_eCEY8","executionInfo":{"status":"ok","timestamp":1722186598846,"user_tz":-540,"elapsed":464,"user":{"displayName":"최이설/메카트로닉스전공/학생","userId":"15230576164295330294"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["%pip install paho-mqtt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C9qZPliV_mop","executionInfo":{"status":"ok","timestamp":1722186197547,"user_tz":-540,"elapsed":5345,"user":{"displayName":"최이설/메카트로닉스전공/학생","userId":"15230576164295330294"}},"outputId":"7410b8bb-9989-4354-b12d-5ac543fccd67"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting paho-mqtt\n","  Downloading paho_mqtt-2.1.0-py3-none-any.whl.metadata (23 kB)\n","Downloading paho_mqtt-2.1.0-py3-none-any.whl (67 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.2/67.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: paho-mqtt\n","Successfully installed paho-mqtt-2.1.0\n"]}]},{"cell_type":"code","source":["!sudo apt-get install mosquitto mosquitto-clients"],"metadata":{"id":"LZZqbzRqJz3_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1722186216111,"user_tz":-540,"elapsed":16018,"user":{"displayName":"최이설/메카트로닉스전공/학생","userId":"15230576164295330294"}},"outputId":"ef0a5dc9-9db7-41e9-fa88-a5dbb047cba9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libcjson1 libdlt2 libev4 libmosquitto1 libwebsockets16 libwrap0\n","Suggested packages:\n","  apparmor\n","The following NEW packages will be installed:\n","  libcjson1 libdlt2 libev4 libmosquitto1 libwebsockets16 libwrap0 mosquitto\n","  mosquitto-clients\n","0 upgraded, 8 newly installed, 0 to remove and 45 not upgraded.\n","Need to get 696 kB of archives.\n","After this operation, 2,079 kB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcjson1 amd64 1.7.15-1 [15.5 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libdlt2 amd64 2.18.6-2 [52.5 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libmosquitto1 amd64 2.0.11-1ubuntu1.1 [51.8 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libev4 amd64 1:4.33-1 [29.4 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libwebsockets16 amd64 4.0.20-2ubuntu1 [188 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwrap0 amd64 7.6.q-31build2 [47.9 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 mosquitto amd64 2.0.11-1ubuntu1.1 [239 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 mosquitto-clients amd64 2.0.11-1ubuntu1.1 [72.4 kB]\n","Fetched 696 kB in 1s (561 kB/s)\n","debconf: unable to initialize frontend: Dialog\n","debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 8.)\n","debconf: falling back to frontend: Readline\n","debconf: unable to initialize frontend: Readline\n","debconf: (This frontend requires a controlling tty.)\n","debconf: falling back to frontend: Teletype\n","dpkg-preconfigure: unable to re-open stdin: \n","Selecting previously unselected package libcjson1:amd64.\n","(Reading database ... 123589 files and directories currently installed.)\n","Preparing to unpack .../0-libcjson1_1.7.15-1_amd64.deb ...\n","Unpacking libcjson1:amd64 (1.7.15-1) ...\n","Selecting previously unselected package libdlt2:amd64.\n","Preparing to unpack .../1-libdlt2_2.18.6-2_amd64.deb ...\n","Unpacking libdlt2:amd64 (2.18.6-2) ...\n","Selecting previously unselected package libmosquitto1:amd64.\n","Preparing to unpack .../2-libmosquitto1_2.0.11-1ubuntu1.1_amd64.deb ...\n","Unpacking libmosquitto1:amd64 (2.0.11-1ubuntu1.1) ...\n","Selecting previously unselected package libev4:amd64.\n","Preparing to unpack .../3-libev4_1%3a4.33-1_amd64.deb ...\n","Unpacking libev4:amd64 (1:4.33-1) ...\n","Selecting previously unselected package libwebsockets16:amd64.\n","Preparing to unpack .../4-libwebsockets16_4.0.20-2ubuntu1_amd64.deb ...\n","Unpacking libwebsockets16:amd64 (4.0.20-2ubuntu1) ...\n","Selecting previously unselected package libwrap0:amd64.\n","Preparing to unpack .../5-libwrap0_7.6.q-31build2_amd64.deb ...\n","Unpacking libwrap0:amd64 (7.6.q-31build2) ...\n","Selecting previously unselected package mosquitto.\n","Preparing to unpack .../6-mosquitto_2.0.11-1ubuntu1.1_amd64.deb ...\n","Unpacking mosquitto (2.0.11-1ubuntu1.1) ...\n","Selecting previously unselected package mosquitto-clients.\n","Preparing to unpack .../7-mosquitto-clients_2.0.11-1ubuntu1.1_amd64.deb ...\n","Unpacking mosquitto-clients (2.0.11-1ubuntu1.1) ...\n","Setting up libmosquitto1:amd64 (2.0.11-1ubuntu1.1) ...\n","Setting up libev4:amd64 (1:4.33-1) ...\n","Setting up libcjson1:amd64 (1.7.15-1) ...\n","Setting up mosquitto-clients (2.0.11-1ubuntu1.1) ...\n","Setting up libwrap0:amd64 (7.6.q-31build2) ...\n","Setting up libdlt2:amd64 (2.18.6-2) ...\n","Setting up libwebsockets16:amd64 (4.0.20-2ubuntu1) ...\n","Setting up mosquitto (2.0.11-1ubuntu1.1) ...\n","invoke-rc.d: could not determine current runlevel\n","invoke-rc.d: policy-rc.d denied execution of start.\n","Created symlink /etc/systemd/system/multi-user.target.wants/mosquitto.service → /lib/systemd/system/mosquitto.service.\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n","\n"]}]},{"cell_type":"code","source":["# difference+MQTT\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from google.colab.patches import cv2_imshow\n","from base64 import b64decode, b64encode\n","import paho.mqtt.client as mqtt\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time\n","import json\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from darknet import *\n","\n","# YOLO model setup\n","cfg_path = 'cfg/yolov4-custom.cfg'\n","data_path = 'data/obj.data'\n","weights_path = '/mydrive/yolov4/training/yolov4-custom_best.weights'\n","network, class_names, class_colors = load_network(cfg_path, data_path, weights_path)\n","width = network_width(network)\n","height = network_height(network)\n","\n","# MQTT 브로커 주소 (공용 MQTT 브로커 사용)\n","broker_address = \"broker.hivemq.com\"  # 공용 브로커 주소\n","port = 1883\n","topic = \"tuk/motor\"\n","topic1 = \"tuk/control\"\n","topic2 = \"tuk/mode\"\n","\n","# topic2에서 받은 메시지를 저장할 변수\n","received_mode_message = \"\"\n","\n","# 메시지가 도착했을 때 호출되는 콜백 함수\n","def on_message(client, userdata, message):\n","    global received_mode_message\n","    if message.topic == topic2:\n","        received_mode_message = str(message.payload.decode('utf-8'))\n","\n","# MQTT 클라이언트 생성 및 설정\n","client = mqtt.Client()\n","client.on_message = on_message\n","\n","# 브로커에 연결\n","client.connect(broker_address, port=port)\n","\n","# 구독 설정\n","client.subscribe(topic2)\n","\n","# 메시지 수신 대기\n","client.loop_start()\n","\n","# darknet helper function to run detection on image\n","def darknet_helper(img, width, height):\n","    darknet_image = make_image(width, height, 3)\n","    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    img_resized = cv2.resize(img_rgb, (width, height), interpolation=cv2.INTER_LINEAR)\n","\n","    # get image ratios to convert bounding boxes to proper size\n","    img_height, img_width, _ = img.shape\n","    width_ratio = img_width / width\n","    height_ratio = img_height / height\n","\n","    # run model on darknet style image to get detections\n","    copy_image_from_bytes(darknet_image, img_resized.tobytes())\n","    detections = detect_image(network, class_names, darknet_image)\n","    free_image(darknet_image)\n","    return detections, width_ratio, height_ratio\n","\n","# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","    image_bytes = b64decode(js_reply.split(',')[1])\n","    jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","    img = cv2.imdecode(jpg_as_np, flags=1)\n","    return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string\n","def bbox_to_bytes(bbox_array):\n","    bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","    iobuf = io.BytesIO()\n","    bbox_PIL.save(iobuf, format='png')\n","    bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","    return bbox_bytes\n","\n","# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","    js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","\n","    var pendingResolve = null;\n","    var shutdown = false;\n","\n","    function removeDom() {\n","        stream.getVideoTracks()[0].stop();\n","        video.remove();\n","        div.remove();\n","        video = null;\n","        div = null;\n","        stream = null;\n","        imgElement = null;\n","        captureCanvas = null;\n","        labelElement = null;\n","    }\n","\n","    function onAnimationFrame() {\n","        if (!shutdown) {\n","            window.requestAnimationFrame(onAnimationFrame);\n","        }\n","        if (pendingResolve) {\n","            var result = \"\";\n","            if (!shutdown) {\n","                captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","                result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","            }\n","            var lp = pendingResolve;\n","            pendingResolve = null;\n","            lp(result);\n","        }\n","    }\n","\n","    async function createDom() {\n","        if (div !== null) {\n","            return stream;\n","        }\n","        div = document.createElement('div');\n","        div.style.border = '2px solid black';\n","        div.style.padding = '3px';\n","        div.style.width = '100%';\n","        div.style.maxWidth = '600px';\n","        document.body.appendChild(div);\n","\n","        const modelOut = document.createElement('div');\n","        modelOut.innerHTML = \"<span>Status:</span>\";\n","        labelElement = document.createElement('span');\n","        labelElement.innerText = 'No data';\n","        labelElement.style.fontWeight = 'bold';\n","        modelOut.appendChild(labelElement);\n","        div.appendChild(modelOut);\n","\n","        video = document.createElement('video');\n","        video.style.display = 'block';\n","        video.width = div.clientWidth - 6;\n","        video.setAttribute('playsinline', '');\n","        video.onclick = () => { shutdown = true; };\n","        stream = await navigator.mediaDevices.getUserMedia(\n","            {video: { facingMode: \"environment\"}});\n","        div.appendChild(video);\n","        imgElement = document.createElement('img');\n","        imgElement.style.position = 'absolute';\n","        imgElement.style.zIndex = 1;\n","        imgElement.onclick = () => { shutdown = true; };\n","        div.appendChild(imgElement);\n","\n","        const instruction = document.createElement('div');\n","        instruction.innerHTML =\n","            '<span style=\"color: red; font-weight: bold;\">' +\n","            'When finished, click here or on the video to stop this demo</span>';\n","        div.appendChild(instruction);\n","        instruction.onclick = () => { shutdown = true; };\n","\n","        video.srcObject = stream;\n","        await video.play();\n","        captureCanvas = document.createElement('canvas');\n","        captureCanvas.width = 640;\n","        captureCanvas.height = 480;\n","        window.requestAnimationFrame(onAnimationFrame);\n","\n","        return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","        if (shutdown) {\n","            removeDom();\n","            shutdown = false;\n","            return '';\n","        }\n","        var preCreate = Date.now();\n","        stream = await createDom();\n","\n","        var preShow = Date.now();\n","        if (label != \"\") {\n","            labelElement.innerHTML = label;\n","        }\n","\n","        if (imgData != \"\") {\n","            var videoRect = video.getClientRects()[0];\n","            imgElement.style.top = videoRect.top + \"px\";\n","            imgElement.style.left = videoRect.left + \"px\";\n","            imgElement.style.width = videoRect.width + \"px\";\n","            imgElement.style.height = videoRect.height + \"px\";\n","            imgElement.src = imgData;\n","        }\n","\n","        var preCapture = Date.now();\n","        var result = await new Promise(function(resolve, reject) {\n","            pendingResolve = resolve;\n","        });\n","        shutdown = false;\n","\n","        return {'create': preShow - preCreate,\n","                'show': preCapture - preShow,\n","                'capture': Date.now() - preCapture,\n","                'img': result};\n","    }\n","    ''')\n","\n","    display(js)\n","\n","def video_frame(label, bbox):\n","    data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","    return data\n","\n","# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialize bounding box to empty\n","bbox = ''\n","a = 0\n","b = 0\n","\n","while True:\n","\n","    # topic1에 screen 메시지 전송\n","    if received_mode_message == \"cus\":\n","      b=b+1\n","      if b==1:\n","        client.publish(topic1, \"screen\")\n","        b=0\n","      #print(b)\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    frame = js_to_image(js_reply[\"img\"])\n","\n","    # create transparent overlays for bounding boxes\n","    bbox_array = np.zeros([480, 640, 4], dtype=np.uint8)\n","    # 추가 바운딩 박스를 위한 새로운 변수 생성\n","    additional_bbox_array = np.zeros([480, 640, 4], dtype=np.uint8)\n","\n","    # call our darknet helper on video frame\n","    detections, width_ratio, height_ratio = darknet_helper(frame, width, height)\n","\n","    for label, confidence, bbox in detections:\n","        left, top, right, bottom = bbox2points(bbox)\n","        left, top, right, bottom = int(left * width_ratio), int(top * height_ratio), int(right * width_ratio), int(bottom * height_ratio)\n","\n","        # 바운딩 박스를 10 픽셀씩 축소\n","        padding_rl = 70\n","        padding_u = 200\n","        padding_d = 100\n","        img_height, img_width, _ = frame.shape\n","        left = max(0, left + padding_rl)\n","        top = max(0, top + padding_u)\n","        right = min(img_width, right - padding_rl)\n","        bottom = min(img_height, bottom - padding_d)\n","\n","        if float(confidence) > 90:\n","          # Create a bounding box\n","          bbox_array = cv2.rectangle(bbox_array, (left, top), (right, bottom), class_colors[label], 2)\n","          bbox_array = cv2.putText(bbox_array, \"{} [{:.2f}]\".format(label, float(confidence)), (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, class_colors[label], 2)\n","          a += 1\n","        else :\n","          #print(\"stop\")\n","          client.publish(topic, \"stop\")\n","          client.publish(topic, json.dumps([0, 0, 0, 0]))\n","\n","    '''\n","    if a == 3:\n","        Add_Box_left = left\n","        Add_Box_top = top\n","        Add_Box_right = right\n","        Add_Box_bottom = bottom\n","    '''\n","\n","    Add_Box_left = 0\n","    Add_Box_top = 162\n","    Add_Box_right = 640\n","    Add_Box_bottom = 428\n","\n","\n","    # additional_bbox_array 바운딩 박스 추가\n","    additional_bbox_array = cv2.rectangle(additional_bbox_array, (Add_Box_left, Add_Box_top), (Add_Box_right, Add_Box_bottom), (255, 0, 0, 255), 2)\n","    #additional_bbox_array = cv2.rectangle(additional_bbox_array, (0,162),(640,428), (255, 0, 0, 255), 2)\n","    additional_bbox_array = cv2.putText(additional_bbox_array, \"Additional Box\", (100, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0, 255), 2)\n","\n","    box_width = right - left\n","    box_height = bottom - top\n","    box_middle_dot_x = left + box_width // 2\n","    box_middle_dot_y = top + box_height // 2\n","    box_area = box_width * box_height\n","    stadard_width = Add_Box_right - Add_Box_left\n","    stadard_height = Add_Box_bottom - Add_Box_top\n","    stadard_middle_dot_x = Add_Box_left + stadard_width // 2\n","    stadard_middle_dot_y = Add_Box_top + stadard_height // 2\n","    stadard_area = stadard_width * stadard_height\n","    left = stadard_middle_dot_x - box_middle_dot_x\n","    right = box_middle_dot_x - stadard_middle_dot_x\n","\n","    # 메시지 수신 대기\n","    client.loop_start()\n","\n","    # topic2에서 받은 메시지가 'cus'인지 확인\n","    if received_mode_message == \"cus\":\n","        # 바운딩 박스 크기 비교\n","        if stadard_area > box_area:\n","            if 0 <= abs(box_middle_dot_x - stadard_middle_dot_x) <= 100:\n","                #print(\"forward\")\n","                client.publish(topic, \"forward\")\n","                client.publish(topic, json.dumps([0, 0, 1, 0]))\n","            elif 100 < stadard_middle_dot_x - box_middle_dot_x:\n","                #print(\"left\")\n","                client.publish(topic, \"left\")\n","                client.publish(topic, json.dumps([0, 0, 0, 1]))\n","            elif 100 < box_middle_dot_x - stadard_middle_dot_x:\n","                #print(\"right\")\n","                client.publish(topic, \"right\")\n","                client.publish(topic, json.dumps([0, 0, 1, 1]))\n","        else:\n","            #print(\"stop\")\n","            client.publish(topic, \"stop\")\n","            client.publish(topic, json.dumps([0, 0, 0, 0]))\n","\n","    # combine both bounding box arrays\n","    combined_bbox_array = cv2.addWeighted(bbox_array, 1.0, additional_bbox_array, 1.0, 0)\n","    combined_bbox_array[:, :, 3] = (combined_bbox_array.max(axis=2) > 0).astype(int) * 255\n","\n","    # convert overlay of bbox into bytes\n","    bbox_bytes = bbox_to_bytes(combined_bbox_array)\n","    # update bbox so next frame gets new overlay\n","    bbox = bbox_bytes\n"],"metadata":{"id":"L9n5kXPMMA_I","colab":{"base_uri":"https://localhost:8080/","height":356},"executionInfo":{"status":"error","timestamp":1722186602279,"user_tz":-540,"elapsed":29,"user":{"displayName":"최이설/메카트로닉스전공/학생","userId":"15230576164295330294"}},"outputId":"2713b37d-63e2-4175-c76d-3c945c069cdc"},"execution_count":19,"outputs":[{"output_type":"error","ename":"OSError","evalue":"/content/gdrive/My Drive/yolov4/darknet/libdarknet.so: cannot open shared object file: No such file or directory","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-184e29c951ae>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdarknet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# YOLO model setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/My Drive/yolov4/darknet/darknet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"posix\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/libdarknet.so\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: /content/gdrive/My Drive/yolov4/darknet/libdarknet.so: cannot open shared object file: No such file or directory"]}]},{"cell_type":"code","source":["# Simple\n","# import dependencies\n","from IPython.display import display, Javascript, Image\n","from google.colab.output import eval_js\n","from google.colab.patches import cv2_imshow\n","from base64 import b64decode, b64encode\n","import cv2\n","import numpy as np\n","import PIL\n","import io\n","import html\n","import time\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","\n","# import darknet functions to perform object detections\n","from darknet import *\n","# load in our YOLOv4 architecture network\n","network, class_names, class_colors = load_network(\"cfg/yolov4-custom.cfg\", \"data/obj.data\", \"/mydrive/yolov4/training/yolov4-custom_best.weights\")\n","width = network_width(network)\n","height = network_height(network)\n","\n","# darknet helper function to run detection on image\n","def darknet_helper(img, width, height):\n","  darknet_image = make_image(width, height, 3)\n","  img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","  img_resized = cv2.resize(img_rgb, (width, height),\n","                              interpolation=cv2.INTER_LINEAR)\n","\n","  # get image ratios to convert bounding boxes to proper size\n","  img_height, img_width, _ = img.shape\n","  width_ratio = img_width/width\n","  height_ratio = img_height/height\n","\n","  # run model on darknet style image to get detections\n","  copy_image_from_bytes(darknet_image, img_resized.tobytes())\n","  detections = detect_image(network, class_names, darknet_image)\n","  free_image(darknet_image)\n","  return detections, width_ratio, height_ratio\n","\n","# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes\n","\n","# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","\n","    var pendingResolve = null;\n","    var shutdown = false;\n","\n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","\n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","\n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","\n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","\n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","\n","      const instruction = document.createElement('div');\n","      instruction.innerHTML =\n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","\n","      video.srcObject = stream;\n","      await video.play();\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","\n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","\n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","\n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","\n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","\n","      return {'create': preShow - preCreate,\n","              'show': preCapture - preShow,\n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","\n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data\n","\n","# start streaming video from webcam\n","video_stream()\n","# label for video\n","label_html = 'Capturing...'\n","# initialze bounding box to empty\n","bbox = ''\n","count = 0\n","while True:\n","    js_reply = video_frame(label_html, bbox)\n","    if not js_reply:\n","        break\n","\n","    # convert JS response to OpenCV Image\n","    frame = js_to_image(js_reply[\"img\"])\n","\n","    # 좌우반전 수행\n","    #frame = cv2.flip(frame, 1)\n","\n","    # create transparent overlay for bounding box\n","    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","\n","\n","    # call our darknet helper on video frame\n","    detections, width_ratio, height_ratio = darknet_helper(frame, width, height)\n","\n","    # loop through detections and draw them on transparent overlay image\n","    for label, confidence, bbox in detections:\n","      left, top, right, bottom = bbox2points(bbox)\n","      left, top, right, bottom = int(left * width_ratio), int(top * height_ratio), int(right * width_ratio), int(bottom * height_ratio)\n","\n","      # 여기서 바운딩 박스를 10 픽셀씩 축소\n","      padding_rl = 70\n","      padding_u = 200\n","      padding_d = 100\n","      img_height, img_width, _ = frame.shape\n","      left = max(0, left + padding_rl)\n","      top = max(0, top + padding_u)\n","      right = min(img_width, right - padding_rl)\n","      bottom = min(img_height, bottom - padding_d)\n","\n","      #bbox_array = cv2.rectangle(bbox_array, (left, top), (right, bottom), class_colors[label], 2)\n","      bbox_array = cv2.rectangle(bbox_array, (left, top), (right, bottom), class_colors[label], 2)\n","      bbox_array = cv2.putText(bbox_array, \"{} [{:.2f}]\".format(label, float(confidence)),(left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,class_colors[label], 2)\n","      #bbox_array = cv2.putText(bbox_array, \"a\",(left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,class_colors[label], 2)\n","\n","    # (100, 100) 위치에 50x50 바운딩 박스 추가\n","    bbox_array = cv2.rectangle(bbox_array, (145, 170), (448, 417), (255, 0, 0, 255), 2)\n","    bbox_array = cv2.putText(bbox_array, \"Additional Box\", (100, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0, 255), 2)\n","\n","    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","    # convert overlay of bbox into bytes\n","    bbox_bytes = bbox_to_bytes(bbox_array)\n","    # update bbox so next frame gets new overlay\n","    bbox = bbox_bytes\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"U6q4J3ZXCGS6","executionInfo":{"status":"error","timestamp":1722186524110,"user_tz":-540,"elapsed":408,"user":{"displayName":"최이설/메카트로닉스전공/학생","userId":"15230576164295330294"}},"outputId":"c9c16c5d-3e70-4cd8-c52d-3189434a4859"},"execution_count":13,"outputs":[{"output_type":"error","ename":"OSError","evalue":"/content/gdrive/MyDrive/yolov4/darknet/libdarknet.so: cannot open shared object file: No such file or directory","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-d208630343ef>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# import darknet functions to perform object detections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdarknet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# load in our YOLOv4 architecture network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_colors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cfg/yolov4-custom.cfg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data/obj.data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/mydrive/yolov4/training/yolov4-custom_best.weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/gdrive/MyDrive/yolov4/darknet/darknet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"posix\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/libdarknet.so\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0mcwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: /content/gdrive/MyDrive/yolov4/darknet/libdarknet.so: cannot open shared object file: No such file or directory"]}]}]}